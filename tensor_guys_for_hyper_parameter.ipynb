{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_train = pd.read_parquet(r\"D:\\hackathon_HOD\\New_training.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_train.drop(['age','sex'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_new_train['malware_status']\n",
    "x = df_new_train.drop(['malware_status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 1)\n",
    "sc_x = StandardScaler()\n",
    "xtrain = sc_x.fit_transform(X_train) \n",
    "xtest = sc_x.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_leaves :  70\n",
      "Accuracy :  0.6550392\n",
      "Num_leaves :  80\n",
      "Accuracy :  0.6557792\n",
      "Num_leaves :  90\n",
      "Accuracy :  0.6561144\n",
      "Num_leaves :  100\n",
      "Accuracy :  0.65652\n",
      "Num_leaves :  110\n",
      "Accuracy :  0.6564624\n",
      "Num_leaves :  120\n",
      "Accuracy :  0.656496\n",
      "Num_leaves :  130\n",
      "Accuracy :  0.6562328\n",
      "Num_leaves :  140\n",
      "Accuracy :  0.6571376\n",
      "Num_leaves :  150\n",
      "Accuracy :  0.6570424\n",
      "Num_leaves :  160\n",
      "Accuracy :  0.6570808\n",
      "Num_leaves :  170\n",
      "Accuracy :  0.6573984\n",
      "Num_leaves :  180\n",
      "Accuracy :  0.6572472\n",
      "Num_leaves :  190\n",
      "Accuracy :  0.6568744\n",
      "Num_leaves :  200\n",
      "Accuracy :  0.6570416\n",
      "Num_leaves :  210\n",
      "Accuracy :  0.6570976\n",
      "Num_leaves :  220\n",
      "Accuracy :  0.6569128\n",
      "Num_leaves :  230\n",
      "Accuracy :  0.6568184\n",
      "Num_leaves :  240\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  250\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  260\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  270\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  280\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  290\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  300\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  310\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  320\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  330\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  340\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  350\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  360\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  370\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  380\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  390\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  400\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  410\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  420\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  430\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  440\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  450\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  460\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  470\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  480\n",
      "Accuracy :  0.6571112\n",
      "Num_leaves :  490\n",
      "Accuracy :  0.6571112\n"
     ]
    }
   ],
   "source": [
    "num_leaves = [70,80,90,100]\n",
    "for i in range(70,500,10):\n",
    "    clf = lgb.LGBMClassifier(max_depth=8, num_leaves=i, min_child_samples=200)\n",
    "    clf.fit(xtrain, y_train)\n",
    "    acc = clf.score(xtest,y_test)\n",
    "    print(\"Num_leaves : \",i),  print(\"Accuracy : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(max_depth=8, num_leaves=180, min_child_samples=200)\n",
    "model.fit(xtrain, y_train)\n",
    "acc = model.score(xtest,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6572472\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\udain\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\hackathon_HOD\\hyper_parameter.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/hackathon_HOD/hyper_parameter.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n_estimators \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m20\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hackathon_HOD/hyper_parameter.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m max_depth \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(trial\u001b[39m.\u001b[39msuggest_loguniform(\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m32\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/hackathon_HOD/hyper_parameter.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m clf \u001b[39m=\u001b[39m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=112121ðŸ˜Ž\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"binary_logloss\",\n",
    "            early_stopping_rounds=100,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, \"binary_logloss\")\n",
    "            ],  # Add a pruning callback\n",
    "        )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model=pickle.dump(model,open('model_lgbm.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd2cc5f8a122bddbd1ec9da99366ffa535cd85facf7b7b81dc79cb5f68f6ab4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
